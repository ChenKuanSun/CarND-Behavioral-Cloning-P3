{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\fgria\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\SDCND\\\\lib\\\\site-packages\\\\')\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, Activation, Lambda, Cropping2D\n",
    "from keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    #Convert to HSV to adjust brightness\n",
    "    HSV_image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    #Add a constant so that it prevents the image from being completely dark\n",
    "    random_bright = .25+np.random.uniform()\n",
    "\n",
    "    #Apply the brightness reduction to the V channel\n",
    "    HSV_image[:,:,2] = HSV_image[:,:,2]*random_bright\n",
    "\n",
    "    #Convert to RBG again\n",
    "    HSV_image = cv2.cvtColor(HSV_image,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    #Cut image\n",
    "    Cut_image = HSV_image[55:135, :, :]\n",
    "\n",
    "    #Convert to np.array\n",
    "    processed_image = Cut_image.astype(np.float32)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    #Normalize\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(80, 320,3)))\n",
    "\n",
    "    model.add(Conv2D(24, 5,5,subsample=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(36, 5,5,subsample=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(48, 5,5,subsample=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(64, 3,3, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Conv2D(64, 3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    project_path = './dataset/'\n",
    "    datalist = os.listdir(project_path)\n",
    "    \n",
    "    for datapath in datalist:\n",
    "        lines = []\n",
    "        print(\"Loading Data: \" + datapath)\n",
    "        with open(project_path + datapath + \"/driving_log.csv\",newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "        print(\"Process image\")\n",
    "        for line in lines:\n",
    "            #Drop some 0 steering data\n",
    "            if float(line[3])== 0.0:\n",
    "                if np.random.choice([True, False]):\n",
    "                    continue\n",
    "            \n",
    "            img_center_filepath = project_path + datapath + '/IMG/' + line[0].split('\\\\')[-1]\n",
    "            img_left_filepath = project_path + datapath + '/IMG/' + line[1].split('\\\\')[-1]\n",
    "            img_right_filepath = project_path + datapath + '/IMG/' + line[2].split('\\\\')[-1]\n",
    "\n",
    "            img_center = process_image(cv2.imread(img_center_filepath))\n",
    "            img_left = process_image(cv2.imread(img_left_filepath))\n",
    "            img_right = process_image(cv2.imread(img_right_filepath))\n",
    "\n",
    "\n",
    "            images.extend([img_center, img_left, img_right])\n",
    "\n",
    "            \n",
    "            steering_center = float(line[3])*1\n",
    "            # create adjusted steering measurement for the side camera images\n",
    "            correction = 0.25 # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            steering_right = steering_center - correction\n",
    "            steering_angles.extend([steering_center, steering_left, steering_right])\n",
    "\n",
    "\n",
    "            #flip\n",
    "            img_center_flipped = np.fliplr(img_center)\n",
    "            img_left_flipped = np.fliplr(img_left)\n",
    "            img_right_flipped = np.fliplr(img_right)\n",
    "\n",
    "            steering_center_flipped = steering_center*-1.0\n",
    "            steering_left_flipped = steering_left*-1.0\n",
    "            steering_right_flipped = steering_right*-1.0\n",
    "            \n",
    "            if np.random.rand() <0.01:\n",
    "                \"\"\"\n",
    "                f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,15))\n",
    "                ax1.imshow(cv2.cvtColor(cv2.imread(img_center_filepath), cv2.COLOR_BGR2RGB))\n",
    "                ax1.set_title('Original Image', fontsize=20)\n",
    "                ax2.imshow(cv2.cvtColor(img_center.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "                ax2.set_title('Random Bright and cut Image', fontsize=20)\n",
    "                ax3.imshow(cv2.cvtColor(img_center_flipped.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "                ax3.set_title('Fliped  Image', fontsize=20)\n",
    "                \"\"\"\n",
    "                #Save image\n",
    "                try:\n",
    "                    mpimg.imsave(\"md_output/\" + \"Original_\" + line[0].split('\\\\')[-1],cv2.cvtColor(cv2.imread(img_center_filepath), cv2.COLOR_BGR2RGB))\n",
    "                    mpimg.imsave(\"md_output/\" + \"Random_Bright_Cut\" + line[0].split('\\\\')[-1],cv2.cvtColor(img_center.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "                    mpimg.imsave(\"md_output/\" + \"Random_Bright_Cut_flipped\" + line[0].split('\\\\')[-1],cv2.cvtColor(img_center_flipped.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "                except FileNotFoundError:\n",
    "                    os.mkdir(\"./md_output\")\n",
    "                    mpimg.imsave(\"md_output/\" + \"Original_\" + line[0].split('\\\\')[-1],cv2.cvtColor(cv2.imread(img_center_filepath), cv2.COLOR_BGR2RGB))\n",
    "                    mpimg.imsave(\"md_output/\" + \"Random_Bright_Cut\" + line[0].split('\\\\')[-1],cv2.cvtColor(img_center.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "                    mpimg.imsave(\"md_output/\" + \"Random_Bright_Cut_flipped\" + line[0].split('\\\\')[-1],cv2.cvtColor(img_center_flipped.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "            images.extend([img_center_flipped, img_left_flipped, img_right_flipped])\n",
    "            steering_angles.extend([steering_center_flipped, steering_left_flipped, steering_right_flipped])\n",
    "\n",
    "    print(\"Dataset complete.\")\n",
    "    X_train = np.array(images)\n",
    "    y_train = np.array(steering_angles)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: data_crush\n",
      "Process image\n",
      "Loading Data: data_fix\n",
      "Process image\n",
      "Loading Data: data_smooth1\n",
      "Process image\n",
      "Loading Data: data_smooth2\n",
      "Process image\n",
      "Loading Data: data_smooth3\n",
      "Process image\n",
      "Loading Data: data_smooth4\n",
      "Process image\n",
      "Dataset complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train = dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fgria\\AppData\\Local\\conda\\conda\\envs\\Crawler\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  \n",
      "C:\\Users\\fgria\\AppData\\Local\\conda\\conda\\envs\\Crawler\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  import sys\n",
      "C:\\Users\\fgria\\AppData\\Local\\conda\\conda\\envs\\Crawler\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  \n",
      "C:\\Users\\fgria\\AppData\\Local\\conda\\conda\\envs\\Crawler\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\fgria\\AppData\\Local\\conda\\conda\\envs\\Crawler\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46225 samples, validate on 19811 samples\n",
      "Epoch 1/10\n",
      "46225/46225 [==============================] - 48s 1ms/step - loss: 0.0478 - val_loss: 0.0270\n",
      "Epoch 2/10\n",
      "46225/46225 [==============================] - 41s 891us/step - loss: 0.0416 - val_loss: 0.0323\n",
      "Epoch 3/10\n",
      "46225/46225 [==============================] - 40s 866us/step - loss: 0.0397 - val_loss: 0.0255\n",
      "Epoch 4/10\n",
      "46225/46225 [==============================] - 41s 881us/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 5/10\n",
      "46225/46225 [==============================] - 40s 870us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 6/10\n",
      "46225/46225 [==============================] - 40s 856us/step - loss: 0.0350 - val_loss: 0.0249\n",
      "Epoch 7/10\n",
      "46225/46225 [==============================] - 40s 859us/step - loss: 0.0334 - val_loss: 0.0256\n",
      "Epoch 8/10\n",
      "46225/46225 [==============================] - 39s 842us/step - loss: 0.0326 - val_loss: 0.0258\n",
      "Epoch 9/10\n",
      "46225/46225 [==============================] - 39s 848us/step - loss: 0.0318 - val_loss: 0.0241\n",
      "Epoch 10/10\n",
      "46225/46225 [==============================] - 39s 847us/step - loss: 0.0309 - val_loss: 0.0252\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 770,619\n",
      "Trainable params: 770,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    tf.keras.backend.set_session(session)\n",
    "    \n",
    "    print(\"Create model\")\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=10)\n",
    "    #model.save('model_test2.h5')\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
